{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "C_ObwItn97MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import subprocess\n",
        "from glob import glob\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import measure\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.ndimage as ndi\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "sys.path.append(\"/content/drive/My Drive/PROJECT/pretrained-models/pretrained-models/pretrained-models.pytorch-master/\")\n",
        "import pretrainedmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "dAOZOk7a97Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_radius(src, img_size, padding=False):\n",
        "    x = src[src.shape[0] // 2, ...].sum(axis=1)\n",
        "    r = (x > x.mean() / 10).sum() // 2\n",
        "    yx = src.sum(axis=2)\n",
        "    region_props = measure.regionprops((yx > yx.mean() / 10).astype('uint8'))\n",
        "    yc, xc = np.round(region_props[0].centroid).astype('int')\n",
        "    x1 = max(xc - r, 0)\n",
        "    x2 = min(xc + r, src.shape[1] - 1)\n",
        "    y1 = max(yc - r, 0)\n",
        "    y2 = min(yc + r, src.shape[0] - 1)\n",
        "    dst = src[y1:y2, x1:x2]\n",
        "    dst = cv2.resize(dst, dsize=None, fx=img_size/(2*r), fy=img_size/(2*r))\n",
        "    if padding:\n",
        "        pad_x = (img_size - dst.shape[1]) // 2\n",
        "        pad_y = (img_size - dst.shape[0]) // 2\n",
        "        dst = np.pad(dst, ((pad_y, pad_y), (pad_x, pad_x), (0, 0)), 'constant')\n",
        "    return dst\n",
        "\n",
        "    \n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None, img_size=288, save_img=True):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "        self.save_img = save_img\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, label = self.img_paths[index], self.labels[index]\n",
        "        \n",
        "        if 'train' in img_path:\n",
        "            img = cv2.imread('/content/drive/My Drive/PROJECT/aptos2019-dataset/images_288_scaled/images_288_scaled/%s' %os.path.basename(img_path))\n",
        "        \n",
        "        else:\n",
        "            if os.path.exists('processed/%s' %os.path.basename(img_path)):\n",
        "                img = cv2.imread('processed/%s' %os.path.basename(img_path))\n",
        "\n",
        "            else:\n",
        "                img = cv2.imread(img_path)\n",
        "                try:\n",
        "                    img = scale_radius(img, img_size=self.img_size, padding=False)\n",
        "                except Exception as e:\n",
        "                    img = img\n",
        "                if self.save_img:\n",
        "                    cv2.imwrite('processed/%s' %os.path.basename(img_path), img)\n",
        "        \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "\n",
        "def get_model(model_name='resnet18', num_outputs=None, pretrained=True,\n",
        "              freeze_bn=False, dropout_p=0, **kwargs):\n",
        "\n",
        "    pretrained = 'imagenet' if pretrained else None\n",
        "    model = pretrainedmodels.__dict__[model_name](num_classes=1000,\n",
        "                                                  pretrained=pretrained)\n",
        "\n",
        "    if 'dpn' in model_name:\n",
        "        in_channels = model.last_linear.in_channels\n",
        "        model.last_linear = nn.Conv2d(in_channels, num_outputs,\n",
        "                                      kernel_size=1, bias=True)\n",
        "    else:\n",
        "        if 'resnet' in model_name:\n",
        "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        else:\n",
        "            model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        in_features = model.last_linear.in_features\n",
        "        if dropout_p == 0:\n",
        "            model.last_linear = nn.Linear(in_features, num_outputs)\n",
        "        else:\n",
        "            model.last_linear = nn.Sequential(\n",
        "                nn.Dropout(p=dropout_p),\n",
        "                nn.Linear(in_features, num_outputs),\n",
        "            )\n",
        "\n",
        "    if freeze_bn:\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.requires_grad = False\n",
        "                m.bias.requires_grad = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-step_size, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def quadratic_weighted_kappa(y_pred, y_true):\n",
        "    if torch.is_tensor(y_pred):\n",
        "        y_pred = y_pred.data.cpu().numpy()\n",
        "    if torch.is_tensor(y_true):\n",
        "        y_true = y_true.data.cpu().numpy()\n",
        "    if y_pred.shape[1] == 1:\n",
        "        y_pred = y_pred[:, 0]\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "    return metrics.cohen_kappa_score(y_pred, y_true, weights='quadratic')\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (input, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        output = model(input)\n",
        "        loss = criterion(output.view(-1), target.float())\n",
        "\n",
        "        # compute gradient and do optimizing step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        thrs = [0.5, 1.5, 2.5, 3.5]\n",
        "        output[output < thrs[0]] = 0\n",
        "        output[(output >= thrs[0]) & (output < thrs[1])] = 1\n",
        "        output[(output >= thrs[1]) & (output < thrs[2])] = 2\n",
        "        output[(output >= thrs[2]) & (output < thrs[3])] = 3\n",
        "        output[output >= thrs[3]] = 4\n",
        "        \n",
        "        target[target < thrs[0]] = 0\n",
        "        target[(target >= thrs[0]) & (target < thrs[1])] = 1\n",
        "        target[(target >= thrs[1]) & (target < thrs[2])] = 2\n",
        "        target[(target >= thrs[2]) & (target < thrs[3])] = 3\n",
        "        target[target >= thrs[3]] = 4\n",
        "        \n",
        "        score = quadratic_weighted_kappa(output, target)\n",
        "\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        scores.update(score, input.size(0))\n",
        "\n",
        "    return losses.avg, scores.avg\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(input)\n",
        "            loss = criterion(output.view(-1), target.float())\n",
        "        \n",
        "            thrs = [0.5, 1.5, 2.5, 3.5]\n",
        "            output[output < thrs[0]] = 0\n",
        "            output[(output >= thrs[0]) & (output < thrs[1])] = 1\n",
        "            output[(output >= thrs[1]) & (output < thrs[2])] = 2\n",
        "            output[(output >= thrs[2]) & (output < thrs[3])] = 3\n",
        "            output[output >= thrs[3]] = 4\n",
        "            score = quadratic_weighted_kappa(output, target)\n",
        "\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            scores.update(score, input.size(0))\n",
        "\n",
        "    return losses.avg, scores.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw2qPM1a97Mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('processed', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO_Le2c397Mz",
        "colab_type": "text"
      },
      "source": [
        "# Pseudo Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYDQdJ5Y97M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pseudo_probs = {}\n",
        "\n",
        "aptos2019_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train.csv')\n",
        "aptos2019_img_paths = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\n",
        "aptos2019_labels = aptos2019_df['diagnosis'].values\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test.csv')\n",
        "dir_name = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test_images'\n",
        "test_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\n",
        "test_labels = np.zeros(len(test_img_paths))\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_set = Dataset(\n",
        "    test_img_paths,\n",
        "    test_labels,\n",
        "    transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYeup1d597NB",
        "colab_type": "text"
      },
      "source": [
        "## SE-ResNeXt50_32x4d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50GeSs-X97NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = get_model(model_name='se_resnext50_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "probs = []\n",
        "for fold in range(5):\n",
        "    print('Fold [%d/%d]' %(fold+1, 5))\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/PROJECT/se-resnext50-32x4d-080922/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    probs_fold = []\n",
        "    with torch.no_grad():\n",
        "        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "\n",
        "            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n",
        "    probs_fold = np.array(probs_fold)\n",
        "    probs.append(probs_fold)\n",
        "\n",
        "probs = np.mean(probs, axis=0)\n",
        "pseudo_probs['se_resnext50_32x4d'] = probs\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk3ygB9n97NP",
        "colab_type": "text"
      },
      "source": [
        "## SE-ResNeXt101_32x4d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DBz18jW97NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = get_model(model_name='se_resnext101_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0,\n",
        "                  )\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "probs = []\n",
        "for fold in range(5):\n",
        "    print('Fold [%d/%d]' %(fold+1, 5))\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/PROJECT/se-resnext101-32x4d-081208/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    probs_fold = []\n",
        "    with torch.no_grad():\n",
        "        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "\n",
        "            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n",
        "    probs_fold = np.array(probs_fold)\n",
        "    probs.append(probs_fold)\n",
        "\n",
        "probs = np.mean(probs, axis=0)\n",
        "pseudo_probs['se_resnext101_32x4d'] = probs\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noy7ikI997Na",
        "colab_type": "text"
      },
      "source": [
        "## SENet154"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8tqNqN97Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = get_model(model_name='senet154',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "probs = []\n",
        "for fold in range(5):\n",
        "    print('Fold [%d/%d]' %(fold+1, 5))\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/PROJECT/senet154-082510/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    probs_fold = []\n",
        "    with torch.no_grad():\n",
        "        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "\n",
        "            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n",
        "    probs_fold = np.array(probs_fold)\n",
        "    probs.append(probs_fold)\n",
        "\n",
        "probs = np.mean(probs, axis=0)\n",
        "pseudo_probs['senet154'] = probs\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTX7OV1z97Nn",
        "colab_type": "text"
      },
      "source": [
        "# Train & Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOOa7CCz97Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_probs = {}\n",
        "\n",
        "train_transform = []\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((288, 288)),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=(-180, 180),\n",
        "        scale=(0.8889, 1.0),\n",
        "        shear=(-36, 36),\n",
        "    ),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0,\n",
        "        contrast=(0.9, 1.1),\n",
        "        saturation=0,\n",
        "        hue=0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKn0ZkS97Nx",
        "colab_type": "text"
      },
      "source": [
        "## SE-ResNeXt50_32x4d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmJRN0cZ97N0",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWcUPDO497N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aptos2019_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train.csv')\n",
        "aptos2019_img_paths = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\n",
        "aptos2019_labels = aptos2019_df['diagnosis'].values\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test.csv')\n",
        "test_img_paths = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test_images/' + test_df['id_code'].values + '.png'\n",
        "test_labels = 0.4 * pseudo_probs['se_resnext50_32x4d'] + 0.3 * pseudo_probs['se_resnext101_32x4d'] + 0.3 * pseudo_probs['senet154']\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=41)\n",
        "img_paths = []\n",
        "labels = []\n",
        "for (train_idx1, val_idx1), (train_idx2, val_idx2) in zip(skf.split(aptos2019_img_paths, aptos2019_labels), kf.split(test_img_paths)):\n",
        "    img_paths.append((np.hstack((aptos2019_img_paths[train_idx1], test_img_paths[val_idx2])), aptos2019_img_paths[val_idx1]))\n",
        "    labels.append((np.hstack((aptos2019_labels[train_idx1], test_labels[val_idx2])), aptos2019_labels[val_idx1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lF4HvbI97N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = get_model(model_name='se_resnext50_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0,\n",
        "                  )\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.MSELoss().cuda()\n",
        "\n",
        "best_losses = []\n",
        "best_scores = []\n",
        "\n",
        "for fold, ((train_img_paths, val_img_paths), (train_labels, val_labels)) in enumerate(zip(img_paths, labels)):\n",
        "    print('Fold [%d/%d]' %(fold+1, len(img_paths)))\n",
        "\n",
        "    # train\n",
        "    train_set = Dataset(\n",
        "        train_img_paths,\n",
        "        train_labels,\n",
        "        transform=train_transform,\n",
        "        img_size=288,\n",
        "        save_img=True)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "\n",
        "    val_set = Dataset(\n",
        "        val_img_paths,\n",
        "        val_labels,\n",
        "        transform=val_transform,\n",
        "        save_img=True)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_set,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2)\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/PROJECT/se-resnext50-32x4d-080922/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    optimizer = RAdam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=10, eta_min=1e-5)\n",
        "    \n",
        "    os.makedirs('se_resnext50_32x4d', exist_ok=True)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_score = 0\n",
        "    for epoch in range(10):\n",
        "        print('Epoch [%d/%d]' % (epoch + 1, 10))\n",
        "\n",
        "        # train for one epoch\n",
        "        train_loss, train_score = train(\n",
        "            train_loader, model, criterion, optimizer, epoch)\n",
        "        # evaluate on validation set\n",
        "        val_loss, val_score = validate(val_loader, model, criterion)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print('loss %.4f - score %.4f - val_loss %.4f - val_score %.4f'\n",
        "              % (train_loss, train_score, val_loss, val_score))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            torch.save(model.state_dict(), 'se_resnext50_32x4d/model_%d.pth' %(fold+1))\n",
        "            best_loss = val_loss\n",
        "            best_score = val_score\n",
        "            print(\"=> saved best model\")\n",
        "\n",
        "    print('val_loss:  %f' % best_loss)\n",
        "    print('val_score: %f' % best_score)\n",
        "    \n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKt8ptxg97OI",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqS_B_nS97OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test.csv')\n",
        "dir_name = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test_images'\n",
        "test_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\n",
        "test_labels = np.zeros(len(test_img_paths))\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_set = Dataset(\n",
        "    test_img_paths,\n",
        "    test_labels,\n",
        "    transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n",
        "\n",
        "# create model\n",
        "model = get_model(model_name='se_resnext50_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "probs = []\n",
        "for fold in range(5):\n",
        "    print('Fold [%d/%d]' %(fold+1, 5))\n",
        "\n",
        "    model.load_state_dict(torch.load('se_resnext50_32x4d/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    probs_fold = []\n",
        "    with torch.no_grad():\n",
        "        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "\n",
        "            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n",
        "    probs_fold = np.array(probs_fold)\n",
        "    probs.append(probs_fold)\n",
        "\n",
        "probs = np.mean(probs, axis=0)\n",
        "l1_probs['se_resnext50_32x4d'] = probs\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luj5MQzY97OS",
        "colab_type": "text"
      },
      "source": [
        "## SE-ResNeXt101_32x4d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9-t0ob297OW",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiBQka2E97OX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aptos2019_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train.csv')\n",
        "aptos2019_img_paths = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\n",
        "aptos2019_labels = aptos2019_df['diagnosis'].values\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test.csv')\n",
        "test_img_paths = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test_images/' + test_df['id_code'].values + '.png'\n",
        "test_labels = 0.4 * pseudo_probs['se_resnext50_32x4d'] + 0.3 * pseudo_probs['se_resnext101_32x4d'] + 0.3 * pseudo_probs['senet154']\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "img_paths = []\n",
        "labels = []\n",
        "for (train_idx1, val_idx1), (train_idx2, val_idx2) in zip(skf.split(aptos2019_img_paths, aptos2019_labels), kf.split(test_img_paths)):\n",
        "    img_paths.append((np.hstack((aptos2019_img_paths[train_idx1], test_img_paths[val_idx2])), aptos2019_img_paths[val_idx1]))\n",
        "    labels.append((np.hstack((aptos2019_labels[train_idx1], test_labels[val_idx2])), aptos2019_labels[val_idx1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QgfmVrt97Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = get_model(model_name='se_resnext101_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0)\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.MSELoss().cuda()\n",
        "\n",
        "best_losses = []\n",
        "best_scores = []\n",
        "\n",
        "for fold, ((train_img_paths, val_img_paths), (train_labels, val_labels)) in enumerate(zip(img_paths, labels)):\n",
        "    print('Fold [%d/%d]' %(fold+1, len(img_paths)))\n",
        "\n",
        "    # train\n",
        "    train_set = Dataset(\n",
        "        train_img_paths,\n",
        "        train_labels,\n",
        "        transform=train_transform,\n",
        "        img_size=288,\n",
        "        save_img=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "\n",
        "    val_set = Dataset(\n",
        "        val_img_paths,\n",
        "        val_labels,\n",
        "        transform=val_transform,\n",
        "        save_img=True)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_set,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2)\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/PROJECT/se-resnext101-32x4d-081208/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    optimizer = RAdam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=10, eta_min=1e-5)\n",
        "    \n",
        "    os.makedirs('se_resnext101_32x4d', exist_ok=True)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_score = 0\n",
        "    for epoch in range(10):\n",
        "        print('Epoch [%d/%d]' % (epoch + 1, 10))\n",
        "\n",
        "        # train for one epoch\n",
        "        train_loss, train_score = train(\n",
        "            train_loader, model, criterion, optimizer, epoch)\n",
        "        # evaluate on validation set\n",
        "        val_loss, val_score = validate(val_loader, model, criterion)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print('loss %.4f - score %.4f - val_loss %.4f - val_score %.4f'\n",
        "              % (train_loss, train_score, val_loss, val_score))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            torch.save(model.state_dict(), 'se_resnext101_32x4d/model_%d.pth' %(fold+1))\n",
        "            best_loss = val_loss\n",
        "            best_score = val_score\n",
        "            print(\"=> saved best model\")\n",
        "\n",
        "    print('val_loss:  %f' % best_loss)\n",
        "    print('val_score: %f' % best_score)\n",
        "    \n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sys0UShB97On",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhsiLwK897Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test.csv')\n",
        "dir_name = '/content/drive/My Drive/PROJECT/aptos2019-blindness-detection/test_images'\n",
        "test_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\n",
        "test_labels = np.zeros(len(test_img_paths))\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_set = Dataset(\n",
        "    test_img_paths,\n",
        "    test_labels,\n",
        "    transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n",
        "\n",
        "# create model\n",
        "model = get_model(model_name='se_resnext101_32x4d',\n",
        "                  num_outputs=1,\n",
        "                  pretrained=False,\n",
        "                  freeze_bn=True,\n",
        "                  dropout_p=0)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "probs = []\n",
        "for fold in range(5):\n",
        "    print('Fold [%d/%d]' %(fold+1, 5))\n",
        "\n",
        "    model.load_state_dict(torch.load('se_resnext101_32x4d/model_%d.pth' % (fold+1)))\n",
        "\n",
        "    probs_fold = []\n",
        "    with torch.no_grad():\n",
        "        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "\n",
        "            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n",
        "    probs_fold = np.array(probs_fold)\n",
        "    probs.append(probs_fold)\n",
        "\n",
        "probs = np.mean(probs, axis=0)\n",
        "l1_probs['se_resnext101_32x4d'] = probs\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1OQ4U1397Ov",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6c8LYKE97Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = 0.5 * l1_probs['se_resnext50_32x4d'] + 0.5 * l1_probs['se_resnext101_32x4d']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWPYha7Y97O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thrs = [0.5, 1.5, 2.5, 3.5]\n",
        "preds[preds < thrs[0]] = 0\n",
        "preds[(preds >= thrs[0]) & (preds < thrs[1])] = 1\n",
        "preds[(preds >= thrs[1]) & (preds < thrs[2])] = 2\n",
        "preds[(preds >= thrs[2]) & (preds < thrs[3])] = 3\n",
        "preds[preds >= thrs[3]] = 4\n",
        "preds = preds.astype('int')\n",
        "\n",
        "test_df['diagnosis'] = preds\n",
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0i6d-xH97PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm processed/*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}